\documentclass{article}
\usepackage{amsmath, amssymb, tikz, geometry, graphicx, natbib, mwe, color, xcolor, listings, tabularx, pdfpages, blindtext, mathtools, stackengine, pgfplots,bigints, relsize, upgreek, esint, array, multirow, schemata, wrapfig, cancel, comment}
\usepackage{hyperref}
\usepackage{slashed, enumitem}
\usepackage{titlesec}
\usetikzlibrary{positioning}

\begin{comment}
code to write section, subsection and subsubsection title in a specific color
\titleformat{\section}
{\color{synthwave_text}\normalfont\Large\bfseries}
{\color{synthwave_text}\thesection}{1em}{} 

\titleformat{\subsection}
{\color{synthwave_text}\normalfont\large\bfseries}
{\color{synthwave_text}\thesubsection}{1em}{} 

\titleformat{\subsubsection}
{\color{synthwave_text}\normalfont\normalfont\bfseries}
{\color{synthwave_text}\thesubsubsection}{1em}{}
\end{comment}


\pgfplotsset{compat=1.9}

\colorlet{myWhite}{white!35!gray}
\definecolor{shadeofgray}{HTML}{181818}
\definecolor{shadeofviolet}{HTML}{0f022c}
\definecolor{synthwave_beckground}{HTML}{252334}
\definecolor{synthwave_text}{HTML}{e148aa}


\hypersetup{
    colorlinks=true,
    linkcolor=violet,
    filecolor=magenta,      
    urlcolor=cyan,
    pdftitle={Controlli Automatici T},
    pdfpagemode=FullScreen,
}


\geometry{ 
 a4paper,
 left=10mm,
 right=10mm,
 top=10mm
 }
 
\lstdefinestyle{mystyle}{ 
bracketsstyle=\color{red}
}

\title{Controlli Automatici T}
\author{Giuseppe Bumma}


% color option
%\pagecolor{synthwave_beckground} %{shadeofgray}
%\color{myWhite}

\renewcommand{\CancelColor}{\color{synthwave_text}}


\begin{document}

%Commands
\newcommand{\R}{\mathbb{R}}
\newcommand{\Varepsilon}{\mathcal{E}}
\newcommand{\rad}{\text{rad}}
\newcommand{\bb}[1]{\mathbb{#1}}
\newcommand{\cc}[1]{\mathcal{#1}}
\newcommand{ \lognormal }{\text{Lognormal} }
\newcommand{\T}[1]{\text{#1}}
\newcommand*\circled[1]{\tikz[baseline=(char.base)]{%
            \node[shape=circle,draw,inner sep=2pt] (char) {#1};}}
%for using circled number in enumerate use:
%\begin{enumerate}[label=\protect\circled{\arabic*}]


\tableofcontents

\maketitle

\section{Introduzione}
L'idea dei \textbf{controlli automatici} è sostituire l'intelligenza umana con un sistema automatico (come l'intelligenza artificiale) basata su leggi matematiche e/o algoritmi.



\subsection{Notazione ed elementi costitutivi}
\begin{center}
    \includegraphics[scale=0.3]{Images/Schema_sistema.png}
\end{center}
Il \textbf{sistema} è un oggetto per il quale si vuole ottenere un comportamento desiderato.
\\
Esempi di sistema sono: impianto (industriale), macchinario (braccio robotico, macchina a controllo numerico, etc\dots), veicolo (auto, velivolo, drone, etc\dots), fenomeno fisico (condizioni atmosferiche), sistema biologico, sistema sociale.
\\
L'obiettivo è che l'andamento nel tempo di alcune variabili segua un segnale di riferimento.
\vspace*{0.2cm}\\
Altri elementi sono:
\begin{itemize}
    \item Controllore: unità che determina l'andamento della variabile di controllo (ingresso);
    \item Sistema di controllo: sistema (processo) + controllore;
    \item Sistemi di controllo naturali: meccanismi presenti in natura, come  quelli presenti nel corpo umano (temperatura corporea costante, ritmo cardiaco, etc\dots);
    \item Sistemi di controllo manuali: è presente l'azione dell'uomo;
    \item Sistemi di controllo automatico: uomo sostituito da un dispositivo.
\end{itemize}




\subsection{Controllo in anello aperto e anello chiuso}
Controllo in anello aperto (“feedforward”): il controllore utilizza solo il segnale di riferimento
\begin{center}
    \includegraphics[scale=0.32]{Images/Anello_aperto.png}
\end{center}
Controllo in anello chiuso (“feedback” o retroazione): il controllore utilizza il segnale di riferimento e la variabile controllata ad ogni istante di tempo
\begin{center}
    \includegraphics[scale=0.3]{Images/Anello_chiuso.png}
\end{center}
Il controllo in retroazione è un paradigma centrale nei controlli automatici.


\subsection{Progetto di un sistema di controllo}
I passi passi per progettare un sistema di controllo sono:
\begin{itemize}
    \item definizione delle specifiche: assegnazione comportamento  desiderato, qualità del controllo, costo,...
    \item modellazione del sistema (controllo e test): complessità del modello (compromesso), definizione ingressi/uscite, codifica del modello, validazione in simulazione
    \item analisi del sistema: studio proprietà “strutturali”, fattibilità specifiche
    \item sintesi legge di controllo: è basata su modello, analisi sistema controllato, stima carico computazionale
    \item simulazione sistema controllato: test su modello di controllo, test realistici (modello complesso, ritardi, quantizzazione, disturbi, ...)
    \item scelta elementi tecnologici: sensori/attuatori, elettronica di acquisizione/attuazione, dispositivo di elaborazione
    \item sperimentazione: hardware in the loop, prototipazione rapida, realizzazione prototipo definitivo
\end{itemize}





\subsection{Esempio di sistema di controllo: circuito elettrico} \label{Circuito elettrico}
\begin{center}
    \includegraphics[scale=0.2]{Images/Es_cirucito_elettrico.png}
\end{center}
La legge che usiamo per definire il circuito (il nostro sistema) è la \textit{legge delle tensioni}
\[
    v_R (t) = v_G (t) - v_C(t)
\] 
le leggi del condensatore e del resistore sono 
\begin{align*}
    C \cdot  \dot v_C (t) &= i(t) & v_R (t) = R\cdot i(t)
\end{align*}
Scrivendo la formula in termini di $v_C (t)$ (“stato interno”) e $v_G (t)$ (“ingresso di controllo”)
\[
    \dot v_C (t) = \frac{1}{RC} \left(v_G (t) - v_C (t) \right)
\]




\section{Sistemi in forma di stato}
\subsection{Sistemi continui}
I \textit{sistemi continuti} sono sistemi in cui il tempo è una variabile reale: $t \in \mathbb{R}$
\begin{align*}
    \dot x(t) &= f \left( x(t), u(t), t \right) & &\text{equazione di stato}\\
    \dot y(t) &= h\left(x(t), u(t), t\right) & &\text{equazione  (trasformazione) di uscita }
\end{align*}
Definiamo inoltre $t_0$ come tempo iniziale e $x(t_0)=x_0$ come stato iniziale. \\
\textbf{N.B.} $\dot x(t) := \dfrac{d}{dt}x(t)$.
\vspace*{0.1cm}\\
Notazione:
\begin{itemize}
    \item $x(t) \in \mathbb{R}^n$ stato del sistema all'istante $t$
    \item $u(t) \in \mathbb{R}^m$ ingresso del sistema all'istante $t$
    \item $y(t) \in \mathbb{R}^p$ uscita del sistema all'istante $t$
\end{itemize}
\[
    x(t)=
    \begin{bmatrix}
        x_1(t)\\
        ...\\
        ...\\
        ...\\
        x_n(t)
    \end{bmatrix}
    \ \ \ \ \ 
    u(t) =
    \begin{bmatrix}
        u_1(t)\\
        ...\\
        ...\\
        ...\\
        u_m(t)
    \end{bmatrix}
    \ \ \ \ \ 
    y(t) = 
    \begin{bmatrix}
        y_1(t)\\
        ...\\
        ...\\
        ...\\
        y_p(t)
    \end{bmatrix}
\]
Da notare che $x(t)$ è un vettore mentre $x_1,...,x_n$ sono scalari.\\
$x(t)$ è una variabile interna che descrive il comportamento del sistema.


\subsubsection{Equazione di stato}
L'\textit{equazione di stato} è un'equazione ordinaria (ODE) vettoriale del primo ordine (cioè l'ordine massimo delle derivate è 1)
\begin{align*}
    \dot x_1(t) &= f_1 \left(x(t), u(t), t\right)\\
    &\dots\\
    \dot x_n (t) &= f_n \left(x(t), u(t), t\right)
\end{align*}
$\mathbb{R}^n$ è detto \underline{spazio di stato}, con $n$ ordine del sistema. La funzione di stato è $f: \mathbb{R}^n \times \mathbb{R}^m \times \mathbb{R} \rightarrow \mathbb{R}^n$.
\[
    \begin{bmatrix}
        \dot x_1(t)\\
        ...\\
        ...\\
        ...\\
        \dot x_n(t)
    \end{bmatrix} 
    =
    \begin{bmatrix}
        f_1\left(x(t),u(t),t\right)\\
        ...\\
        ...\\
        ...\\
        f_n\left(x(t),u(t),t\right)
    \end{bmatrix}
    := f\left(x(t),u(t),t\right)
\]
Avere solo derivate prime non è limitato, perché ad esempio posso inserire una prima variabile come derivata prima e una seconda variabile come derivata prima della prima variabile.

\subsubsection{Equazione di uscita}
L'equazione di uscita è un'equazione algebrica
\begin{align*}
    y_1(t) &= h_1 \left(x(t), u(t), t\right)\\
    &\dots\\
    y_p (t) &= h_p \left(x(t), u(t), t\right)
\end{align*}
$h : \mathbb{R}^n \times \mathbb{R}^m , \mathbb{R} \rightarrow R^p$ funzione di uscita
\[
    \begin{bmatrix}
        y_1(t)\\
        ...\\
        ...\\
        ...\\
        y_p(t)
    \end{bmatrix} 
    =
    \begin{bmatrix}
        h_1\left(x(t),u(t),t\right)\\
        ...\\
        ...\\
        ...\\
        h_p\left(x(t),u(t),t\right)
    \end{bmatrix}
    := h\left(x(t),u(t),t\right)
\]
\vspace*{0.2cm}
Se la soluzione $x(t)$ a partire da un istante iniziale $t_0$ è univocamente determinata da $x(t_0)$ e $u(\tau)$ con $\tau \geq t_0$, allora il sistema è detto \textbf{causale}, cioè lo stato dipende solo da ciò che accede in passato.\\
Sotto opportune ipotesi di regolarità della funzione $f$ si dimostra esistenza e unicità della soluzione dell'equazione (differenziale) di stato (Teorema di Cauchy-Lipschitz).



\subsection{Sistemi discreti}
Nei \textit{sistemi discreti} il tempo $t$ è una variabile intera, $t \in \mathbb{Z}$.
\begin{align*}
    x(t+1) &= f \left(x(t), u(t), t\right) & &\text{equazione di stato}\\
    y(t) &= h\left(x(t), u(t), t\right) & &\text{equazione (trasformazione) di uscita}
\end{align*}
L'equazione di stato è un'equazione alle differenze finite (FDE).
\vspace*{0.2cm}\\
Notazione:
\begin{itemize}
    \item $x(t) \in \mathbb{R}^n$ stato  del sistema all'istante $t$
    \item $u(t) \in \mathbb{R}^m$ ingresso del sistema all'istante $t$
    \item $y(t) \in \mathbb{R}^p$ uscita del sistema all'istante $t$
\end{itemize}
$x(t),u(t) \text{ e } y(t)$ sono uguali ai sistemi continui.\\
Per modellare sistemi discreti nel codice basta un ciclo {\fontfamily{lmtt}\selectfont for}.



\subsection{Esempio circuito elettrico}
Riprendiamo l'esempio del \hyperlink{Circuito elettrico}{circuito elettrico}; la formula trovata è 
\[
    \underbrace{\dot v_C(t)}_{\dot x(t)} = \frac{1}{RC} (\underbrace{v_G (t)}_{u(t)} - \underbrace{v_C (t)}_{x(t)} )
\]
In questo caso lo stato del sistema $x(t)$ è caratterizzato dalla variabile $v_C(t)$, l'ingresso dalla variabile $v_G(t)$. Supponiamo quindi di misurare (con un sensore) la tensione ai capi della resistenza, allora l'uscita del nostro sistema sarà $v_R(t)$
\begin{align*}
    \dot x(t) &= \frac{1}{RC} \left(u(t)-x(t)\right) &
    f(x,u) &= \frac{1}{RC}(u-x)
\end{align*}
da notare che in questo caso $f$ non è funzione del tempo.
\[
    v_R(t) = v_G(t) - v_C(t) \Longrightarrow y(t) = u(t) - x(t)
\]


\subsubsection{Esempio con parametri che variano nel tempo}
Supponiamo che la resistenza sia una funzione del tempo
\[
    R(t) = \overline{R} \left(1- \frac{1}{2} e^{-t} \right)
\]
allora 
\begin{align*}
    \dot x(t) &= \frac{1}{R(t)C} \left(u(t)-x(t)\right) &
    f(x,u,t) &= \frac{1}{R(t)C}(u-x)
\end{align*}
in questo caso $f$ è funzione del tempo.



\subsection{Esempio carrello}
\begin{center}
    \includegraphics[scale=0.2]{Images/Es_carrello.png}
\end{center}
La legge che usiamo è la legge di Newton, prendendo $z$ come posizione del centro di massa
\[
    M \ddot  z = -F_e + F_m
\]
con $M$ massa e $F_e$ data da
\[
    F_e (z(t), t) = k(t)z(t)
\]
quindi la nostra equazione diventa
\[
    M \ddot  z(t) = -k(t)z(t) + F_m(t)
\]
Siccome nella nostra formula compare una derivata seconda di una variabile ci conviene definire lo stato del sistema con la variabile stessa e la derivata prima della variabile.\\
Definiamo quindi $x_1 := z$ e $x_2:=\dot z$, con stato $x := [x_1x_2]^T$, e $u := F_m$ (ingresso).
\vspace*{0.1cm}\\
Quindi possiamo scrivere, tenendo conto che $\dot x_2(t) = \ddot z$
\begin{align*}
    \dot x_1(t) &= x_2(t)\\
    \dot x_2(t) &= -\frac{k}{M} x_1(t) + \frac{u(t)}{M}
\end{align*}
\[
    f(x,u) = 
    \begin{bmatrix}
        f_1(x,u)\\
        f_2(x,u)
    \end{bmatrix}
    :=
    \begin{bmatrix}
        x_2\\
        -\dfrac{k}{M}x_1+\dfrac{u}{M}
    \end{bmatrix}
\]
Supponiamo di misurare $z(t)$ (sensore posizione), allora $y := z$
\begin{align*}
    \dot x_1(t) &= x_2(t)\\
    \dot x_2(t) &= -\frac{k}{M} x_1(t) + \frac{u(t)}{M}\\
    y(t) &= x_1(t)
\end{align*}
Sia $k(t) = k$ e, ricordando la formula dell'energia cinetica $E_{k}={\dfrac {1}{2}}mv^{2}$ e la formula dell'energia elastica $U={\dfrac {1}{2}}k\,\Delta x^{2}$, consideriamo come uscita l'energia totale $E_T (t) = \dfrac{1}{2} (k z^2 (t) + M \dot z^2 (t))$
\begin{align*}
    \dot x_1(t) &= x_2(t)\\
    \dot x_2(t) &= -\frac{k}{M} x_1(t) + \frac{u(t)}{M}\\
    y(t) &= \frac{1}{2} \left(k(t) x_1^2 (t) + M  x_2^2 (t)\right)
\end{align*}
quindi $h(x):= \dfrac{1}{2} (kx_1^2 + Mx_2^2)$.\\
\textbf{N.B.} Il risultato (l'uscita) vale, di solito, solo per il mio modello, in base a come l'ho impostato; nella realtà potrebbe essere diverso.


\subsection{Esempio auto in rettilineo}
\begin{center}
    \includegraphics[scale=0.18]{Images/Es_Rettilineo.png}
\end{center}
Scriviamo la legge di Newton
\[
    M \ddot z = F_{\text{drag}} + F_m
\]
con $M$ massa e $F_{\text{drag}}$ data da
\[
    F_{\text{drag}} = -b \dot z
\]
Definiamo $x_1 := z$ e $x_2 := \dot z$ (stato $x := [x_1 x_2 ]^T$ ) e $u := F_m$ (ingresso). Supponiamo di misurare $z(t)$ (sensore posizione), allora $y := z$
\begin{align*}
    \dot x_1(t) &= x_2(t)\\
    \dot x_2(t) &= - \frac{b}{M} x_2(t) + \frac{1}{M}u(t)\\
    y(t) &= x_1(t)
\end{align*}
Proviamo a progettare un sistema per il \textit{cruise control}.\\
L'equazione della dinamica è
\[
    M \ddot z(t) = -b\dot z(t) + F_m (t)
\]
Siccome siamo interessati a controllare la velocità e non la posizione, allora consideriamo come stato solo la velocità: $x := \dot z$, $u := F_m$. Supponiamo di misurare $\dot z(t)$ (sensore velocità), allora $y := x$
\begin{align*}
    \dot x(t) &= - \frac{b}{M}x(t) + \frac{1}{M}u(t)\\
    y(t) &= x(t)
\end{align*}



\subsection{Esempio pendolo}
\begin{center}
    \includegraphics[scale=0.17]{Images/Es_pendolo.png}
\end{center}
Scriviamo l'equazione dei momenti
\[
    M \ell^2 \ddot \theta= C_{\T{grav}} + C_{\T{drag}} + C_m
\]
con $M$ massa e $C_{\T{grav}}$ e $C_{\T{drag}}$ date da
\begin{align*}
    C_{\T{grav}} &=M g \ell \sin(\theta) &
    C_{\T{drag}} &= -b \dot \theta
\end{align*}
con $b$ coefficiente d'attrito.
\vspace*{0.2cm}\\
Scriviamo l'equazione della dinamica, partendo dalla formula iniziale dei momenti

\[
    \ddot \theta(t) = -\frac{g}{\ell} \sin \left(\theta(t)\right) - \frac{b}{M \ell^2} \dot \theta(t) + \frac{1}{M \ell^2} C_m(t)
\]
Definiamo quindi $x_1 := \theta$ e $x_2 := \dot \theta$ (stato $x:= [x_1x_2]^T$) e $u := C_m$ (ingresso).\\
Supponiamo di misurare $\theta$ (sensore angolo) , allora $y := \theta$
\begin{align*}
    \dot x_1 (t) &= x_2(t)\\
    \dot x_2(t) &= -\frac{g}{\ell} \sin \left(x_1(t)\right) - \frac{b}{M \ell^2} x_2(t) + \frac{1}{M \ell^2} u(t)\\
    y(t) &= x_1(t)
\end{align*}
Se misuriamo invece la posizione verticale, allora $y := - \ell \cos(\theta)$ 
\begin{align*}
    \dot x_1 (t) &= x_2(t)\\
    \dot x_2(t) &= -\frac{g}{\ell} \sin \left(x_1(t)\right) - \frac{b}{M \ell^2} x_2(t) + \frac{1}{M \ell^2} u(t)\\
    y(t) &= - \ell \cos(\theta)
\end{align*}



\subsection{Traiettoria di un sistema}
Dato un istante iniziale $t_0$ e uno stato iniziale $x_{t_0}$, la funzione del tempo $(x(t), u(t)), \ t>t_0$, che soddisfa l'equazione di stato $\dot x(t) = f (x(t), u(t), t)$ si dice traiettoria (movimento) del sistema. In particolare, $x(t)$ si dice traiettoria dello stato. Consistentemente, $y(t)$ si dice traiettoria dell'uscita.
\vspace*{0.2cm}\\
\textbf{N.B.} per sistemi senza ingresso (quindi non forzati) la traiettoria dello stato $x(t), \ t>t_0$ è determinata solo dallo stato iniziale $x_{t_0}$.


\subsubsection{Esempio}
Definiamo un sistema con stato $x$ e stato iniziale $x_0$
\begin{align*}
    x &:=
    \begin{bmatrix}
        x_1\\
        x_2
    \end{bmatrix}
    &
    x_0 &:=
    \begin{bmatrix}
        5\\
        3
    \end{bmatrix}
    &
    t_0 &= 0
\end{align*}
\begin{align*}
    \dot x_1(t) &= x_2(t)\\
    \dot x_2(t) &= u(t)
\end{align*}
Assegno a $x_1$, $x_2$ e $u(t)$ le seguenti equazioni
\begin{align*}
    \overline{x_1}(t) &= 5+3t+t^2\\
    \overline{x_2}(t) &= 3+2t\\
    \overline{u}(t) &= 2
\end{align*}
Se le equazioni di $\overline{x_1}$ e $\overline{x_2}$ soddisfano le condizioni iniziali e la funzione di stato ($\dot x_1$ e $\dot x_2$) allora quelle equazioni sono la traiettoria del sistema.\\
Infatti
\[
    \overline{x_0} = 
    \begin{bmatrix}
        5+3t+t^2\\
        3+2t
    \end{bmatrix}_{t=0} 
    =
    \begin{bmatrix}
        5\\
        3
    \end{bmatrix}
\]
\begin{align*}
    &\overline{x_0} = 
    \begin{bmatrix}
        5+3t+t^2\\
        3+2t
    \end{bmatrix}_{t=0} 
    =
    \begin{bmatrix}
        5\\
        3
    \end{bmatrix}
    &
    \frac{d}{dt} 
    \begin{bmatrix}
        5+3t+t^2\\
        3+2t
    \end{bmatrix}
    =
    \begin{bmatrix}
        3+2t\\
        2
    \end{bmatrix}
\end{align*}



\subsection{Equilibrio di un sistema}
Dato un sistema (non forzato) $\dot x(t) = f (x(t), t)$, uno stato $x_e$ si dice \textit{equilibrio del sistema} se $x(t) = x_e$ , $t\geq t_0$ è una traiettoria del sistema.
\vspace*{0.2cm}\\
Dato un sistema (forzato) $\dot x(t) = f (x(t), u(t), t)$, $(x_e , u_e )$ si dice \textit{coppia di equilibrio} del sistema se $(x(t), u(t)) = (x_e , u_e )$, $t \geq t_0$ , è una traiettoria del sistema.
\vspace*{0.2cm}\\
Per un sistema (tempo invariante continuo) $\dot x(t) = f (x(t), u(t))$ data una coppia di equilibrio $(x_e,u_e)$ vale $f(x_e,u_e)=0$.\\
Se il sistema è non forzato, dato un equilibrio $x_e$ vale $f(x_e)=0$.


\subsubsection{Esempio pendolo}
\begin{align*}
    \dot x_1(t) &= x_2(t) &= f_1(x(t),u(t))\\
    \dot x_2(t) &= - \frac{G}{\ell} \sin (x_1(t)) - \frac{b}{M \ell ^2}x_2(t) + \frac{1}{M\ell^2}u(t) &=f_2(x(t),u(t))
\end{align*}
Siccome sappiamo che, data una coppia di equilibrio $(x_e,u_e)$, vale $f(x_e,u_e)=0$, allora per trovare l'equilibrio del pendolo imponiamo 
\[
    f(x_e,u_e)=0
\]
cioè:
\[
    \begin{cases}
        x_{2e}(t) = 0\\
        \\
        - \dfrac{G}{\ell} \sin (x_{1e}) - \dfrac{b x_{2e}}{M \ell ^2} + \dfrac{1}{M\ell^2}u_e =0
    \end{cases}
\]
sostituendo $x_{2e}(t)=0$ nell'ultima equazione
\[
    - \dfrac{G}{\ell} \sin (x_{1e}) + \dfrac{1}{M\ell^2}u_e =0 \Longrightarrow u_e = M G \ell \sin(x_{1e})
\]
In conclusione, le coppie di equilibrio del sistemo sono tutti fli $(x_{1e}, x_{2e},u_e)$ che soddisfano
\[
    \begin{cases}
        u_e = M G \ell \sin(x_{1e})\\
        x_{2e}=0
    \end{cases}
\]




\subsection{Classificazione dei sistemi in forma di stato}
La classe generale è  $x \in \mathbb{R}^n , u \in \mathbb{R}^m , y\in \mathbb{R}^p$
\begin{align*}
    \dot x(t) &= f (x(t), u(t), t) & &\T{equazione di stato}\\
    y(t) &= h(x(t), u(t), t) & &\T{equazione di uscita}  
\end{align*}
\begin{itemize}
    \item I sistemi \textbf{monovariabili} (SISO, Single Input Single Output) sono una sottoclasse di sistemi \textbf{multivariabili} (MIMO, Multiple Input Multiple Output); sono tali se $m=p=1$, altrimenti sono dei sistemi MIMO;
    \item I sistemi \textbf{strettamente propri} sono una sotto classe dei \textbf{sistemi propri}; sono tali se $y(t) = h(x(t),t))$, quindi se l'uscita dipende esclusivamente dall'ingresso, chiamati quindi sistemi causali (tutti i sistemi che abbiamo visto fin'ora sono sistemi propri).
    \item I sistemi \textbf{non forzati} sono una sotto classe dei \textbf{sistemi forzati}; un esempio di sistema non forzato è il seguente
    \begin{align*}
        \dot x(t) &= f(x(t),t)\\
        y(t) &= h(x(t),t)
    \end{align*}
    \item I sistemi \textbf{tempo invarianti} sono una sotto classe di sistemi \textbf{tempo  varianti}.\\
    I tempo invarianti sono tali se, data una traiettoria $ (x(t), u(t)), t\geq t_0$, con $x(t_0)=x_0$, per ogni $\Delta \in \mathbb{R}$ vale che $x(t_0+\Delta)=x_0$ allora $(x_{\Delta} (t), u_{\Delta} (t)) = (x(t-\Delta), u(t-\Delta))$ è una traiettoria.\\
    Si può dimostrare che sistemi tempo invarianti sono del tipo
    \begin{align*}
        \dot x(t) &= f (x(t), u(t)) &x(0)=x_0\\
        y(t) &= h(x(t), u(t))
    \end{align*}
    e senza senza perdita di generalità possiamo scegliere $t_0=0$.\\
    Graficamente:
    \begin{center}
        \includegraphics[scale=0.3]{Images/Sistemi_tempo_invarianti.png}
    \end{center}
    \item I \textbf{sistemi lineari} sono una sotto classe di \textbf{sistemi non lineari}.\\
    I sistemi lineari sono tali se le funzioni di stato e di uscita sono lineari in $x$ e $u$:
    \begin{align*}
        \dot x_1 (t) &= a_{11} (t)x_1 (t) + a_{12} (t)x_2 (t) + . . . + a_{1n} (t)x_n (t)+ b_{11} (t)u_1 (t) + b_{12} (t)u_2 (t) + . . . + b_{1m} (t)u_m (t)\\
        \dot x_2 (t) &= a_{21} (t)x_1 (t) + a_{22} (t)x_2 (t) + . . . + a_{2n} (t)x_n (t)+ b_{21} (t)u_1 (t) + b_{22} (t)u_2 (t) + . . . + b_{2m} (t)u_m (t)\\
        ...\\
        ...\\
        ...\\
        \dot x_n (t) &= a_{n1} (t)x_1 (t) + a_{n2} (t)x_2 (t) + . . . + a_{nn} (t)x_n (t)+ b_{n1} (t)u_1 (t) + b_{n2} (t)u_2 (t) + . . . + b_{nm} (t)u_m (t)
    \end{align*}
    per $y(t)$ invece 
    \begin{align*}
        y_1 (t) &= c_{11} (t)x1 (t) + c_{12} (t)x_2 (t) + . . . + c_{1n} (t)x_n (t)+ d_{11} (t)u_1 (t) + d_{12} (t)u_2 (t) + . . . + d_{1m} (t)u_m (t)\\
        y_2 (t) &= c_{21} (t)x_1 (t) + c_{22} (t)x_2 (t) + . . . + c_{2n} (t)x_n (t)+ d_{21} (t)u_1 (t) + d_{22} (t)u_2 (t) + . . . + d_{2m} (t)u_m (t)\\
        ...\\
        ...\\
        ...\\
        y_p (t) &= c_{p1} (t)x_1 (t) + c_{p2} (t)x_2 (t) + . . . + c_{pn} (t)x_n (t)+ d_{p1}(t)u_1 (t) + d_{p2} (t)u_2 (t) + . . . + d_{pm} (t)u_m (t)
    \end{align*}
\end{itemize}



\subsection{Proprietà dei sistemi lineari}
\subsubsection{Sistemi lineri in forma matriciale}
Definiamo le matrici $A(t) \in \mathbb{R}^{n \times n} , B(t) \in \mathbb{R}^{n \times m} , C(t) \in \mathbb{R}^{p \times n} , D(t) \in \mathbb{R}^{p \times m}$
\begin{align*}
    A(t) &= \begin{bmatrix}
        a_{11}(t) & ... & a_{1n}(t)\\
        .\\
        .\\
        a_{n1}(t) & ... & a_{nn}(t)
    \end{bmatrix}
    &
    B(t) &= \begin{bmatrix}
        b_{11}(t) & ... & b_{1m}(t)\\
        .\\
        .\\
        b_{n1}(t) & ... & b_{nm}(t)
    \end{bmatrix}\\
    C(t) &= \begin{bmatrix}
        c_{11}(t) & ... & c_{1n}(t)\\
        .\\
        .\\
        c_{p1}(t) & ... & c_{pn}(t)
    \end{bmatrix}
    &
    D(t) &= \begin{bmatrix}
        d_{11}(t) & ... & d_{1m}(t)\\
        .\\
        .\\
        d_{pn1}(t) & ... & d_{pm}(t)
    \end{bmatrix}
\end{align*}
quindi scriviamo
\[
    \begin{bmatrix}
        \dot x_1(t)\\
        .\\
        .\\
        \dot x_n(t)
    \end{bmatrix}
    = A(t)
    \begin{bmatrix}
        x_1(t)\\
        .\\
        .\\
        x_n(t)
    \end{bmatrix}
    + B(t)
    \begin{bmatrix}
        u_1(t)\\
        .\\
        .\\
        u_m(t)
    \end{bmatrix}
\]
che equivale a 
\begin{align*}
    \dot x(t) &= A(t) x(t) + B(t) u(t)\\
    y(t) &= C(t)x(t) + D(t) u(t)
\end{align*}


\subsection{Sistemi lineari tempo-invarianti}
\begin{align*}
    \dot x(t) = A x(t) + B u(t)\\
    y(t) = C x(t) + D u(t)
\end{align*}
con $A,B,C,D$ matrici costanti.


\subsubsection{Esempio carrello}
\begin{center}
    \includegraphics[scale=0.2]{Images/Es_carrello.png}
\end{center}
\begin{align*}
    \dot x_1(t) &= x_2(t) & f_1(x,u,t) &= x_2\\
    \dot x_2(t) &= - \frac{k(t)}{M}x_1(t) + \frac{1}{M} u(t) & f_2(x,u,t) &= - \frac{k(t)}{M}x_1 + \frac{1}{M}u\\
    y(t) &= x_1(t)
\end{align*}
$f_2$ dipende esplicitamente da $t$ attraverso $k(t)$ quindi è un sistema tempo \underline{variante}. Se $k(t) = \overline{k}$ per ogni $t$ allora tempo \underline{invariante}.\\
Siccome $f_1$ e $f_2$ dipendono linearmente da $x$ e $u$ il sistema è \underline{lineare}. (Se $k(t) = \overline{k}$ il sistema è \underline{lineare tempo invariante}.)
\begin{align*}
    \begin{bmatrix}
        \dot x_1(t)\\
        \dot x_2(t)
    \end{bmatrix}
    &=
    \underbrace{\begin{bmatrix}
        0 & 1\\
        -\frac{k(t)}{M} & 0
    \end{bmatrix}}_{A}
    \begin{bmatrix}
        x_1(t)\\
        x_2(t)
    \end{bmatrix}
    +
    \underbrace{\begin{bmatrix}
        0\\
        \frac{1}{M}
    \end{bmatrix}}_{B}
    u(t)
    \\
    y(t) &= 
    \underbrace{\begin{bmatrix}
        1 & 0
    \end{bmatrix}}_{C}
    \begin{bmatrix}
        x_1(t)\\
        x_2(t)
    \end{bmatrix}
    + \underbrace{0}_D u(t)
\end{align*}
per $k$ costante:
\begin{align*}
    A &= \begin{bmatrix}
        0 & 1\\
        - \frac{k}{M} & 0
    \end{bmatrix}
    &
    B &= 
    \begin{bmatrix}
        0\\
        1
    \end{bmatrix}
    &
    C &= 
    \begin{bmatrix}
        1 & 0
    \end{bmatrix}
\end{align*}


\subsubsection{Sistemi lineari tempo-invarianti SISO}
I sistemi lineari tempo-invarianti single input single output (SISO) sono caratterizzati dalle matrici $A \in \mathbb{R}^{n \times n} , B \in \mathbb{R}^{n \times 1}, C \in \mathbb{R}^{1 \times n} , D \in \mathbb{R}^{1 \times 1}$, ovvero $B$ è un vettore, $C$ è un vettore riga e $D$ è uno scalare.


\subsection{Principio di sovrapposizione degli effetti}
Prendiamo un sistema lineare (anche tempo-variante)
\begin{align*}
    \dot x(t) &= A(t)x(t) + B(t)u(t)\\
    y(t) &= C(t)x(t) + D(t)u(t)
\end{align*}
Sia $(x_a (t), u_a (t))$ traiettoria con $x_a (t_0)$ = $x_{0a}$.\\
Sia $(x_b (t), u_b (t))$ traiettoria con $x_b (t_0)$ = $x_{0b}$.
\vspace*{0.1cm}\\
Allora $\forall \alpha, \beta \in \mathbb{R}$ dato lo stato iniziale $x_{ab}(t_0) = \alpha x_{0a}+\beta x_{0b}$, si ha che
\[
    (x_{ab}(t), u_{ab}(t)) = (\alpha x_{a}(t) + \beta x_b(t), \alpha u_a(t)+\beta u_b(t))
\]
è traiettoria del sistema, ovvero applicando come ingresso $u_{ab}=\alpha u_a(t) + \beta u_b(t)$ la traiettoria di stato è $x_{ab} (t) = \alpha x_a (t) + \beta x_b (t)$
\[
    \begin{rcases}
        \alpha x_{0a}(t)+\beta x_{0b}(t)\\
        \alpha u_a(t) + \beta u_b(t)(t)
    \end{rcases}
    \Longrightarrow
    \alpha x_a(t) + \beta x_b(t)
\]
\vspace*{0.2cm}
\textbf{IMPORTANTE:} non vale per i sistemi non lineari.

\subsubsection*{Dimostrazione}
Per dimostrarlo dobbiamo provare che soddisfa l'equazione differenziale
\begin{align*}
    \frac{d}{dt}x_{ab}(t) &= \alpha \dot x_a(t) + \beta \dot x_b(t)\\
    &= \alpha(A(t)x_a (t) + B(t)u_a (t)) + \beta (A(t)x_b (t) + B(t)u_b (t))\\
    &= A(t)(\alpha x_a (t) + \beta x_b (t)) + B(t)( \alpha u_a (t) + u_b (t))
\end{align*}
Per sistemi lineari sotto opportune ipotesi su $A(t)$ e $B(t)$ si può dimostrare che la soluzione è unica.\\
Si dimostra lo stesso anche per l'uscita.


\subsection{Evoluzione libera e evoluzione forzata}
Sfruttando il principio di sovrapposizione degli effetti prendiamo due sistemi \circled{A} e \circled{B} 
\begin{align*}
   \circled{A} \ x(t_0) &= x_0 =x_{0a} {\color{violet} \neq 0} & \circled{B} \ \ \ x_{0b}&=0\\
    u_a(t) &= 0 \ \ \forall t \geq t_0 & u_b(t) &= u(t) {\color{violet}\neq 0}
\end{align*}
chiamiamo $x_a(t)=x_\ell(t)$ e $x_b(t) = x_f(t)$
\begin{align*}
    \alpha x_{0a} + \beta x_{0b} &= \underbrace{\alpha}_{1} x_0 = x_0 & 
    \alpha u_a(t) + \beta u_b(t) &= \underbrace{\beta}_{1}u(t) = u(t)
\end{align*}
quindi
\[
    x_{ab}(t) = \underbrace{x_\ell(t)}_{\substack{\text{evoluzione} \\ \text{libera}}} + \underbrace{x_f(t)}_{\substack{\text{evoluzione} \\ \text{forzata}}}
\]
L'\textbf{evoluzione libera} è definita come $x_\ell(t)$ per $t \geq t_0$, tale che $x_\ell (t_0)=x_0$ e $u_l(t)=0$ per $t \geq t_0$, e uscita $y_\ell(t)=C(t)x_\ell(t)$.\\
L'\textbf{evoluzione forzata} è definita come $x_f(t)$ per $t \geq t_0$, tale che $x_f (t_0)=0$ e $u_l(t)=u(t)$ per $t \geq t_0$, e uscita $y_f(t)=C(t)x_f(t)+D(t)u(t)$.
\vspace*{0.2cm}\\
\textbf{IMPORTANTE:} non vale per i sistemi non lineari.


\subsubsection{Traiettorie di un sistema LTI: esempio scalare}
Definiamo un sistema lineare tempo invariante (LTI) scalare $x \in \mathbb{R}$, $u \in \mathbb{R}$, $y \in \mathbb{R}$
\begin{align*}
    \dot x(t) &= ax(t) + bu(t) &x(0) = x_0\\
    y(t) &= cx(t) + du(t)
\end{align*}
dall'analisi matematica possiamo scrivere il sistema come soluzione omogenea + soluzione particolare
\begin{align*}
    x(t) &= e^{at}x_0 + \int_0^t e^{a(t-\tau)}bu(\tau) d \tau \\
    y(t) &= ce^{at}x_0 + c \int_0^t e^{a(t-\tau)}bu(\tau) d \tau + du(t)
\end{align*}
ricordiamo che la funzione esponenziale si può scrivere come
\[
    e^{at} = 1 + at + \frac{(at)^2}{2!} + \frac{(at)^3}{3!} + ...
\]


\subsubsection{Traiettorie di un sistema LTI: caso generale}
Definiamo un sistema lineare tempo invariante (LTI) $x\in \mathbb{R}^n, u\in \mathbb{R}^m, y\in \mathbb{R}^p$
\begin{align*}
    \dot x(t) &= Ax(t) + Bu(t) &x(0) = x_0\\
    y(t) &= Cx(t) + Du(t)
\end{align*}
\begin{align*}
    \underbrace{x(t)}_{\mathbb{R}^n} &= \underbrace{e^{At}}_{\mathbb{R}^{n \times n}} \underbrace{x_0}_{\mathbb{R}^n} + \int_0^t e^{A(t-\tau)}Bu(\tau) d \tau \\
    y(t) &= Ce^{at}x_0 + c \int_0^t e^{A(t-\tau)}Bu(\tau) d \tau + Du(t)
\end{align*}

Ricordiamo che l'esponenziale di matrice si può scrivere come
\[
    e^{At} = I + At + \frac{(At)^2}{2!} + \frac{(At)^3}{3!} + ...
\]
\[
    x(t) = \underbrace{e^{At} x_0}_{\substack{\text{evoluzione} \\ \text{libera}}} + \underbrace{\int_0^t e^{A(t-\tau)}Bu(\tau) d \tau}_{\substack{\text{evoluzione} \\ \text{forzata}}}
\]
\begin{align*}
    x_\ell(t) &= e^{At}x_0 & x_f(t) &= \int_0^t e^{A(t-\tau)}Bu(\tau) d \tau
\end{align*}


\subsubsection{Esempio sistema non forzato}
\begin{align*}
    \dot x_1(t) = \lambda_1 x_1(t) & \dot x_1(t) = \lambda_2 x_2(t)
\end{align*}
\[
    \begin{bmatrix}
        \dot x_1(t)\\
        \dot x_2(t)
    \end{bmatrix}
    =
    \underbrace{\begin{bmatrix}
        \lambda_1 & 0\\
        0 & \lambda_2  
    \end{bmatrix}}_{A}
    \begin{bmatrix}
        x_1(t)\\
        x_2(t)
    \end{bmatrix}
\]
$A := \Lambda$ matrice diagonale.
\vspace*{0.2cm}\\
Il nostro è un sistema non forzato, quindi c'è solo l'evoluzione libera:
\[
    x(t) = e^{\Lambda t}x_0
\]
\begin{align*}
    e^{\Lambda t} &= 
    \begin{bmatrix}
        1 & 0\\
        0 & 1
    \end{bmatrix}
    +
    \begin{bmatrix}
        \lambda_1 & 0\\
        0 & \lambda_2
    \end{bmatrix}
    +
    \begin{bmatrix}
        \lambda_1 & 0\\
        0 & \lambda_2
    \end{bmatrix}^2 \frac{t^2}{2!} + ...\\
    &=\begin{bmatrix}
        1 & 0\\
        0 & 1
    \end{bmatrix}
    +
    \begin{bmatrix}
        \lambda_1 & 0\\
        0 & \lambda_2
    \end{bmatrix}
    +
    \begin{bmatrix}
        \frac{\lambda_1^2 t^2}{2!} & 0\\
        0 & \frac{\lambda_2^2 t^2}{2!}
    \end{bmatrix} + ...\\
    e^{at} = 1 + at + \frac{(at)^2}{2!} + \frac{(at)^3}{3!} + ... \Longrightarrow&=
    \begin{bmatrix}
        e^{\lambda_1 t} & 0\\
        0 & e^{\lambda_2 t}
    \end{bmatrix}
\end{align*}
Quindi nel caso generale di $\Lambda \in \mathbb{R}^{n \times n}$
\[
    e^{\Lambda t} = 
    \begin{bmatrix}
        e^{\lambda_1 t} & 0 & ... & 0\\
        0 & e^{\lambda_2 t} & ... & 0\\
        .\\
        .\\
        0 & ... & 0 & e^{\lambda_n t}
    \end{bmatrix}
\]


\subsubsection{Proprietà della matrice esponenziale}
Esponenziale e cambio di base:
\[
    e^{TAT^{-1}} = Te^{At}T^{-1}
\]
Data una matrice $A \in \mathbb{R}^{n \times n}$, esiste $J$ matrice diagonale a blocchi, chiamata \textit{matrice di Jordan}, che è unica a meno di permutazioni dei blocchi, tale che
\[
    A = T^{-1} J T
\]
con $T$ matrice invertibile (matrice del cambio base). Questa formula viene chiamata \textit{forma di Jordan}.
\vspace*{0.2cm}\\
La matrice di Jordan è fatta in questo modo
\begin{center}
    \includegraphics[scale=0.13]{Images/Jordan_matrix.png}
\end{center}
con $\lambda_i$ autovalore di $A$.
\vspace*{0.2cm}\\
Utilizzando questa forma riconduco il calcolo di $e^{At}$ al calcolo di 
\[
    e^{
        \begin{bmatrix} 
            \lambda & 1 & 0 & ... & 0\\
            0 & ... & ... & ... &0\\
            ... & ... & ... & ... & 0\\
            ... & ... & ... & ... & 1\\
            0 & ... & ... & 0 & \lambda
        \end{bmatrix}
        }
        = e^{\lambda t}
        \begin{bmatrix}
            1 & t & \frac{t^2}{2!} & ... \\
            0 & 1 & t & \frac{t^2}{2!} & ... \\
            ... & ... & ... & ... & ...\\
            0 & ... & ... & ... & 1
        \end{bmatrix}
\]
\textbf{IMPORTANTE:} tutti gli elementi di $e^{At}$ sono del tipo
\[
    t^qe^{\lambda t}
\]
con $q$ intero e $\lambda_i$ autovalori di A


\subsection{Rappresentazioni equivalenti}
Effettuiamo un cambio di base mediante una matrice $T$
\[
    \hat x(t) = T x(t)
\]
ed essendo $T$ invertibile
\[
    x(t) = T^{-1} \hat x(t)
\]
Sostituendo nell'equazione della dinamica si ottiene
\begin{align*}
    {\color{violet} T \cdot} \underbrace{T^{-1} \dot{\hat x}(t)}_{\dot x(t)} &= A \underbrace{T^{-1} \hat x(t)}_{x(t)} + B u(t) {\color{violet} \cdot T } \\
\end{align*}
\begin{align*}
    \dot{\hat x}(t) &= TAT^{-1} \hat x(t) + T B u(t)\\
    y(t) &= CT^{-1} \hat x(t) + D u(t)
\end{align*}
Allora chiamo $\hat A = TAT^{-1}, \hat B=TB, \hat C = CT^{-1}, \hat D = D$
\begin{align*}
    \dot{\hat x}(t)  &= \hat A \hat x(t) + \hat B u(t)\\
    y(t) &= \hat C \hat x(t) + \hat D u(t)
\end{align*}
se $T$ è una matrice tale che
\[
    J = TAT^{-1}
\]
allora
\[
    \dot{\hat x} = J \hat x(t) + T B u(t)
\]
\begin{align*}
    \hat x_\ell (t) = e^{JT} \hat x_0 = T^{-1} e^{Jt}T x_0
\end{align*}




\subsection{Modi di un sistema lineare tempo invariante}
Prendiamo un sistema lineare tempo invariante con $x \in \mathbb{R}^n, u \in \mathbb{R}^m, y \in \mathbb{R}^p$ e $x(0)=x_0$
\begin{align*}
    \dot x(t) &= A x(t) + B u(t)\\
    y(t) &= C x(t) + D u(t)
\end{align*}
Indichiamo con $\lambda_1,...,\lambda_r$ gli $r \leq n$ autovalori (reali o complessi coniugati) distinti della matrice $A$, con molteplicità algebrica $n_1,...,n_r \geq 0$ tali che $\sum\limits ^r_{i=1} n_i = n$.\\
Le componenti dell'evoluzione libera dello stato $x_\ell(t)$ si possono scrivere come
\[
    x_{\ell,j} = \sum^r_{i=1}\sum^{h_i}_{q=1} \gamma_{jiq}t_{q-1}e^{\lambda_i t} \tag*{$j=1,...,n$}
\]
per opportuni valori di $h_i \leq n_i$, dove i coefficienti $\gamma_{jiq}$ dipendono dallo stato iniziale $x(0)$.\\
I termini $t^{q-1}e^{\lambda_i t}$  sono detti modi naturali del sistema.
L'evoluzione libera dello stato è combinazione lineare dei modi.


\subsubsection{Autovalori complessi}
Se la matrice $A$ è reale e $\lambda_i = \sigma_i + j \omega_i$ è un autovalore complesso, allora il suo complesso coniugato $\overline{\lambda}_i = \sigma_i - j \omega_i$ è anch'esso autovalore di $A$.\\
Inoltre si dimostra che i coefficienti $\gamma_{jiq}$ corrispondenti a $\lambda_i$ e $\overline{\lambda}_i$ sono anch'essi complessi coniugati.\\
Scriviamo l'\textbf{esponenziale di autovalori complessi coniugati}; se $\lambda_i = \sigma_i + j \omega_i$ e $\overline{\lambda}_i = \sigma_i - j \omega_i$ allora
\begin{align*}
    e^{\lambda_i t} &= e^{\sigma_i + j \omega_i} & e^{\overline{\lambda}_i t} &= e^{\sigma_i - j \omega_i}\\
    &= e^{\sigma_i t} e^{j \omega_i t} & &= e^{\sigma_i t} e^{-j \omega_i t}\\
    &= e^{\sigma_i t} (\cos(\omega_i t) + j \sin(\omega_i t)) & &= e^{\sigma_i t} (\cos(\omega_i t) - j \sin(\omega_i t))
\end{align*}
Si verifica quindi, per calcolo diretto, che le soluzioni $x_{\ell,j}(t)$ sono sempre reali e che i modi del sistema corrispondenti ad autovalori complessi coniugati $\lambda_i$ e $\overline{\lambda}_i$ sono del tipo
\[
    t^{q-1} e^{\sigma_i t} \cos (\omega_i t + \phi_i)
\]
con opportuni valori della fase $\phi_i$.
\vspace*{0.2cm}\\
Supponiamo che le molteplicità algebriche $n_1,...,n_r$ degli autovalori di $A$ coincidano cone le molteplicità geometriche (ad esempio quando gli autovalori sono distinti).\\
Allora i coefficienti $h_i$ sono tutti pari a 1 e l'espressione dei modi si semplifica in 
\begin{align*}
    &e^{\lambda_i t} & &\T{per autovalori reali}\\
    &e^{\sigma _i t} \cos (\omega_i t + \phi_i) & &\T{per autovalori complessi coniugati}
\end{align*}

\subsubsection*{Modi naturali: autovalori reali semplici}
\begin{center}
    \includegraphics[scale=0.23]{Images/Autovalori_semplici.png}
\end{center}


\subsubsection*{Modi naturali: autovalori complessi coniugati semplici}
\begin{center}
    \includegraphics[scale=0.23]{Images/Autovalori_comlessi.png}
\end{center}

\begin{center}
    \includegraphics[scale=0.23]{Images/Esempio_autovalori.png}
\end{center}

\subsubsection{Esempio sui modi naturali}
\[
    \begin{bmatrix}
        \dot x_1\\
        \dot x_2
    \end{bmatrix}
    =
    \begin{bmatrix}
        0 & 1\\
        a^2 & 0
    \end{bmatrix}
    \begin{bmatrix}
        x_1\\
        x_2
    \end{bmatrix}
\]

\begin{align*}
    p(\lambda) &= \det (\lambda I -A)\\
    &= \lambda^2 - a^2\\
    &\Rightarrow \begin{cases}
        \lambda_1 = a\\
        \lambda_2 = -a
    \end{cases}
\end{align*}
I modi naturali di questo sistema sono 
\begin{align*}
    &e^{at} & &e^{-at}
\end{align*}
Il modo $e^{at}$ diverge a infinito, il che non è una cosa "buona" per dei sistemi di controllo, perché ad esempio se si sta realizzando un sistema di controllo della velocità vuol dire che la mia velocità sta aumentando, mentre dovrebbe rimanere fissa in un range.\\
Non bisogna quindi focalizzarsi sul calcolare con precisione il valore dei modi naturali ma è importante conoscere come si comporta la loro parte reale.


\subsubsection{Esempio 1}
Consideriamo il seguente sistema LTI con $x \in \mathbb{R}^3 e u \in \mathbb{R}^3$
\[
    \dot x(t) = \underbrace{\begin{bmatrix}
        0 & 1 & -1\\
        1 & -1 & -1\\
        2 & 1 & 3 
    \end{bmatrix}}_{A} x(t) +
    \underbrace{\begin{bmatrix}
        1 & 1 & 0\\
        0 & 1 & 1\\
        1 & 1 & 1
    \end{bmatrix}}_{B} u(t)
\]
Mediante un cambio di coordinate usando la matrice $T = \begin{bmatrix}
    0 & -1 & 1\\ 1 & 1 & -1\\ -1 & 0 & 1
\end{bmatrix}$ e ponendo $\hat x(t) = T x(T)$, il sistema si può riformulare come 
\[
    \hat{\dot x} (t)= \underbrace{\begin{bmatrix}
        -1 & 1 & 0\\
        0 & -1 & 0\\
        0 & 0 & -2 
    \end{bmatrix}}_{\hat A = TAT^{-1}} \hat x(t) +
    \underbrace{\begin{bmatrix}
        1 & 0 & 0\\
        0 & 1 & 0\\
        0 & 0 & 1
    \end{bmatrix}}_{\hat B = TB} u(t)
\]
Gli autovalori di $\hat A$ sono $-1, -2$ con molteplicità algebrica $2,1$.
\vspace*{0.2cm}\\
Per calcolare l'evoluzione libera consideriamo la formula vista in precedenza
\[
    \hat x_\ell  =e^{\hat A t}\hat x_0
\]
Calcoliamo quindi l'esponenziale di matrice $e^{\hat A t}$ per $\hat A = \begin{bmatrix}
    -1 & 1 & 0\\
    0 & -1 & 0\\
    0 & 0 & -2
\end{bmatrix}$
\begin{align*}
    e^{\hat A t} &= \sum_{k=0}^\infty \begin{bmatrix}
        -1 & 1 & 0\\
        0 & -1 & 0\\
        0 & 0 & -2
    \end{bmatrix}^k \frac{t^k}{k!}\\
    &= \begin{bmatrix}
        \sum\limits_{k=0}^\infty \frac{(-1)^k t^k}{k!} & t \sum\limits_{k=0}^\infty \frac{(-1)^k t^k}{k!} & 0\\
        0 & \sum\limits_{k=0}^\infty \frac{(-1)^k t^k}{k!} & 0\\
        0 & 0 & \sum\limits_{k=0}^\infty \frac{(-2)^k t^k}{k!}
    \end{bmatrix}\\
    &= \begin{bmatrix}
        e^{-t} & te^{-t} & 0\\
        0 & e^{-t} & 0\\
        0 & 0 & e^{-2t}
    \end{bmatrix}
\end{align*}
quindi l'evoluzione libera dello stato è
\[
    \hat x_\ell = 
    \begin{bmatrix}
        e^{-t} & te^{-t} & 0\\
        0 & e^{-t} & 0\\
        0 & 0 & e^{-2t}
    \end{bmatrix} \hat x_0
\]
\begin{itemize}
\item Se ad esempio la condizione iniziale è $\hat x_0 = \begin{bmatrix} 1\\0\\0 \end{bmatrix}$, allora
\[
    \hat x_\ell = \begin{bmatrix} e^{-t}\\0\\0 \end{bmatrix}
\]
Scriviamolo nello coordinate originali
\[
    x_\ell(t) = \underbrace{\begin{bmatrix}
        1&1&0\\
        0&1&1\\
        1&1&1
    \end{bmatrix}}_{T^{-1}} \hat x_\ell (t) = 
    \begin{bmatrix}
        e^{-t}\\
        0\\
        e^{-t}
    \end{bmatrix}
\]
\item Se prendiamo come condizione iniziale $\hat x_0 = \begin{bmatrix} 0\\1\\0 \end{bmatrix}$, allora
\[
    \hat x_\ell = \begin{bmatrix} te^{-t}\\e^{-t}\\0 \end{bmatrix}
\]
Scriviamolo nello coordinate originali
\[
    x_\ell(t) = \underbrace{\begin{bmatrix}
        1&1&0\\
        0&1&1\\
        1&1&1
    \end{bmatrix} }_{T^{-1}} \hat x_\ell (t) = 
    \begin{bmatrix}
        e^{-t} + te^{-t}\\
        e^{-t}\\
        e^{-t} + te^{-t}
    \end{bmatrix}
\]


\item Se prendiamo come condizione iniziale $\hat x_0 = \begin{bmatrix} 0\\0\\1 \end{bmatrix}$. allora
\[
    \hat x_\ell = \begin{bmatrix} 0\\0\\e^{-2t} \end{bmatrix}
\]
Nelle coordinate originali:
\[
    x_\ell(t) = \underbrace{\begin{bmatrix}
        1&1&0\\
        0&1&1\\
        1&1&1
    \end{bmatrix} }_{T^{-1}} \hat x_\ell (t) = 
    \begin{bmatrix}
        0\\
        e^{-2t}\\
        e^{-2t}
    \end{bmatrix}
\]

\end{itemize}


\subsubsection{Esempio carrello}
\begin{align*}
    \begin{bmatrix}
        \dot x_1(t)\\
        \dot x_2(t)
    \end{bmatrix} &=
    \begin{bmatrix}
        0 & 1\\
        - \frac{k}{M} & 0
    \end{bmatrix}
    \begin{bmatrix}
        x_1(t)\\
        x_2(t)
    \end{bmatrix}
    +
    \begin{bmatrix}
        0\\
        \frac{1}{M}
    \end{bmatrix} u(t)
    \\
    y(t) &= \begin{bmatrix}
        1 & 0
    \end{bmatrix}
    \begin{bmatrix}
        x_1(t)\\
        x_2(t)
    \end{bmatrix} + 0 u(t)
\end{align*}
Consideriamo $k$ costante, quindi sistema LTI.\\
Gli autovalori della matrice $A$ sono $\lambda_1 = j \sqrt{\dfrac{k}{M}}, \lambda_2 = -j \sqrt{\dfrac{k}{M}}$ immaginari puri.
\vspace*{0.2cm}\\
Applichiamo un controllo $u = - hx_2$
































































\end{document}